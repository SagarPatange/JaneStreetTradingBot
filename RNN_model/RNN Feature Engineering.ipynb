{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea0f00f-d5c1-4ca7-9b36-3ea672267074",
   "metadata": {},
   "source": [
    "## Load and Analyze CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c90109-0526-4638-a5c1-552e12553a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to features.csv\n",
    "features_file = \"/path/to/features.csv\"\n",
    "\n",
    "# Load features.csv\n",
    "features_df = pd.read_csv(features_file)\n",
    "\n",
    "# Analyze tags\n",
    "tags = [col for col in features_df.columns if \"tag\" in col]\n",
    "features_by_tag = {tag: features_df[features_df[tag] == True][\"feature\"].tolist() for tag in tags}\n",
    "\n",
    "# Summary of features by tag\n",
    "for tag, features in features_by_tag.items():\n",
    "    print(f\"{tag}: {len(features)} features\")\n",
    "\n",
    "# Save the features grouped by tags for further exploration\n",
    "features_by_tag_df = pd.DataFrame(dict([(tag, pd.Series(features)) for tag, features in features_by_tag.items()]))\n",
    "features_by_tag_df.to_csv(\"/path/to/features_by_tag.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17e641-e0a6-4d53-a22d-5aabf1a6f1c5",
   "metadata": {},
   "source": [
    "## Load and Sample Data from Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fdd30-9d5b-4a96-b2af-cc5f6d5a763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to training data directory\n",
    "data_dir = \"/path/to/train.parquet\"\n",
    "partitions = [f\"partition_id={i}\" for i in range(10)]\n",
    "\n",
    "# Initialize a DataFrame to collect random samples\n",
    "sampled_data = pd.DataFrame()\n",
    "\n",
    "# Randomly sample rows from each partition\n",
    "for partition in partitions:\n",
    "    partition_path = os.path.join(data_dir, partition)\n",
    "    print(f\"Processing {partition}...\")\n",
    "    df = pd.read_parquet(partition_path, engine=\"pyarrow\")\n",
    "    sampled_partition = df.sample(n=500, random_state=42)  # Adjust `n` based on memory\n",
    "    sampled_data = pd.concat([sampled_data, sampled_partition], ignore_index=True)\n",
    "\n",
    "print(f\"Sampled data shape: {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483cb52-9f6f-499a-9a06-083fc2fe8664",
   "metadata": {},
   "source": [
    "##  Analyze and Filter Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f321834d-6ef8-480c-928c-26e382c2fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "target_col = \"responder_6\"\n",
    "\n",
    "# Drop columns with >50% missing values\n",
    "nan_threshold = 0.5\n",
    "valid_features = sampled_data.columns[sampled_data.isna().mean() < nan_threshold]\n",
    "filtered_data = sampled_data[valid_features]\n",
    "\n",
    "# Calculate correlations with the target\n",
    "correlations = filtered_data.corr()[target_col].drop(target_col).sort_values(ascending=False)\n",
    "\n",
    "# Identify top positively and negatively correlated features\n",
    "top_positive_features = correlations.head(10).index.tolist()\n",
    "top_negative_features = correlations.tail(10).index.tolist()\n",
    "\n",
    "print(\"Top positively correlated features:\")\n",
    "print(correlations.head(10))\n",
    "\n",
    "print(\"\\nTop negatively correlated features:\")\n",
    "print(correlations.tail(10))\n",
    "\n",
    "# Combine top features for final selection\n",
    "final_features = top_positive_features + top_negative_features + [target_col]\n",
    "\n",
    "# Filter data to only include selected features\n",
    "filtered_data = filtered_data[final_features]\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "filtered_data.dropna(inplace=True)\n",
    "\n",
    "print(f\"Filtered data shape: {filtered_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58ad3f-dfa0-4381-ab5d-0d1ee56abeb3",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
