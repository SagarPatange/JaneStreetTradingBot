{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":10400610,"sourceType":"datasetVersion","datasetId":6444358},{"sourceId":10455538,"sourceType":"datasetVersion","datasetId":6472200},{"sourceId":10455759,"sourceType":"datasetVersion","datasetId":6472340},{"sourceId":10455899,"sourceType":"datasetVersion","datasetId":6472422}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport polars as pl\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import VarianceThreshold\nimport joblib  # For loading preprocessing objects\nimport tensorflow as tf\nimport os\n\n# ------------------------------\n# 1. Custom Loss\n# ------------------------------\ndef weighted_r2_loss(y_true, y_pred):\n    \"\"\"\n    Weighted R^2 loss for the competition\n    \"\"\"\n    weights = tf.abs(y_true)\n    numerator = tf.reduce_sum(weights * tf.square(y_true - y_pred))\n    denominator = tf.reduce_sum(weights * tf.square(y_true))\n    return numerator / denominator\n\n# ------------------------------\n# 2. Load the Model\n# ------------------------------\n# Update this path to match your Kaggle dataset name\nmodel_path = \"/kaggle/input/mlp-model-h5/mlp_model_no_metrics.h5\"\nmlp_model = load_model(model_path, custom_objects={\"weighted_r2_loss\": weighted_r2_loss})\n\n# ------------------------------\n# 3. Load Preprocessing Objects\n# ------------------------------\n# Update this path to match your uploaded preprocessing dataset name in Kaggle\nvariance_threshold_path = \"/kaggle/input/processing/variance_threshold.pkl\"\nscaler_path = \"/kaggle/input/processing/scaler.pkl\"\npca_path = \"/kaggle/input/processing/pca.pkl\"\nexpected_features_path = \"/kaggle/input/expected/expected_features.pkl\"\n\n# Load preprocessing objects\nvariance_threshold = joblib.load(variance_threshold_path)\nscaler = joblib.load(scaler_path)\npca = joblib.load(pca_path)\nexpected_features = joblib.load(expected_features_path)\n\nprint(\"Preprocessing objects and expected features loaded.\")\n\n# ------------------------------\n# 4. Preprocessing Function\n# ------------------------------\ndef preprocess_data(df):\n    \"\"\"\n    Preprocess the data to match the training pipeline.\n    \"\"\"\n    # Ensure the test data matches the expected features\n    df = df[expected_features]  # Select only the expected features\n    \n    # Handle missing values\n    df.fillna(0, inplace=True)\n    \n    # Apply preprocessing steps\n    features_high_variance = variance_threshold.transform(df.values)\n    features_scaled = scaler.transform(features_high_variance)\n    features_pca = pca.transform(features_scaled)\n    \n    return features_pca\n\n\n# ------------------------------\n# 5. Prediction Function\n# ------------------------------\n# Global variable for lagged data\nlags_ = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None = None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"\n    Predict function for the competition inference server.\n    \"\"\"\n    global lags_\n    if lags is not None:\n        lags_ = lags  # Update global lags with new values\n    \n    # Convert to pandas and preprocess\n    test_df = test.to_pandas()\n    test_features = preprocess_data(test_df)\n    \n    # Make predictions\n    predictions = mlp_model.predict(test_features)\n    \n    # Return predictions in the required format\n    return test.select(\n        pl.col(\"row_id\"),\n        pl.lit(predictions.flatten()).alias(\"responder_6\")\n    )\n\n# ------------------------------\n# 6. Inference Server Setup\n# ------------------------------\nimport kaggle_evaluation.jane_street_inference_server as inference_server\n\n# Initialize the inference server\ninference_server = inference_server.JSInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    # Serve the model for the competition rerun\n    inference_server.serve()\nelse:\n    # Run locally for testing\n    # Run locally for testing\n    inference_server.run_local_gateway((\n        \"/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet\",\n        \"/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet\"\n    ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T04:53:21.135143Z","iopub.execute_input":"2025-01-13T04:53:21.135554Z","iopub.status.idle":"2025-01-13T04:53:41.720141Z","shell.execute_reply.started":"2025-01-13T04:53:21.135522Z","shell.execute_reply":"2025-01-13T04:53:41.718817Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator VarianceThreshold from version 1.6.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.6.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator PCA from version 1.6.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Preprocessing objects and expected features loaded.\n\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step","output_type":"stream"},{"name":"stderr","text":"<ipython-input-13-2dec440bc131>:60: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df.fillna(0, inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n","output_type":"stream"}],"execution_count":13}]}